{
 "metadata": {
  "name": "",
  "signature": "sha256:94ace873d6ea4fc0ec2a24c3669e0244bd9a569aeef6ca93a1551cfe6254683d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Wiley Bookbinder"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some functions to get all chapters of a book from Wiley Online Library and combine the PDF files into a single file. Works only with completely accessible books, but is not limited to freely available books. Access depends on your institute's contract with Wiley."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The user provided URL for a book should look like this:\n",
      "\n",
      "> http://onlinelibrary.wiley.com/book/10.1002/9780470385951\n",
      "\n",
      "The single chapters are accessed like this by the functions:\n",
      "\n",
      "> http://onlinelibrary.wiley.com/doi/10.1002/9780470385951.fmatter\n",
      "\n",
      "> http://onlinelibrary.wiley.com/doi/10.1002/9780470385951.ch1\n",
      "\n",
      "The according PDF file pages are accessed like this by the functions:\n",
      "\n",
      "> http://onlinelibrary.wiley.com/doi/10.1002/9780470385951.fmatter/pdf\n",
      "\n",
      "> http://onlinelibrary.wiley.com/doi/10.1002/9780470385951.ch1/pdf\n",
      "\n",
      "The link to each PDF is inside the 'src' of an 'iframe' on the latter pages:\n",
      "```html\n",
      "<iframe id=\"pdfDocument\" src=\"http://onlinelibrary.wiley.com/store/10.1002/9780470385951.fmatter/asset/fmatter.pdf?v=1&amp;t=i9pmwvio&amp;s=90f1cb510c74dde3fa70d21d4934bd27c81e03af\" width=\"100%\" height=\"675px\"></iframe>\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Usage:\n",
      "1. The URL of the book's webpage\n",
      "2. The path to save the files to\n",
      "3. The name for the final PDF file (Limited to 30 characters, file extension not needed)\n",
      "\n",
      "```\n",
      "getwileybook(url = 'http://onlinelibrary.wiley.com/book/10.1002/0471227587', \n",
      "             path = 'WileyBooks/DNA-MAD', \n",
      "             title = 'Analysis of DNA Microarray Data')\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#TODO switch to Python 3\n",
      "#TODO automatically create folders, currently the user needs to do it before running the script\n",
      "\n",
      "import os\n",
      "import urllib, urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "from PyPDF2 import PdfFileMerger, PdfFileReader\n",
      "\n",
      "def getlinks(url, baseurl = 'http://onlinelibrary.wiley.com'):\n",
      "    # TODO also accept DOI instead of full URL\n",
      "    # TODO what if it is not a book?\n",
      "    # TODO error handling\n",
      "    request = urllib2.Request(url)\n",
      "    response = urllib2.urlopen(request)\n",
      "    page = response.read()\n",
      "    #print page\n",
      "    soup = BeautifulSoup(page)\n",
      "    links = soup.find_all(class_ = 'standardPdfLink') # will this list always be ordered?\n",
      "    print \"Found %i chapters for your request.\\n\" % len(links)\n",
      "    urldict = {}\n",
      "    for i in range(len(links)):\n",
      "        link = baseurl + links[i]['href']\n",
      "        urldict[i] = link\n",
      "    return urldict\n",
      "\n",
      "def getpdflinks(urldict):\n",
      "    pdfdict = {}\n",
      "    for i in range(len(urldict)):\n",
      "        link = urldict[i]\n",
      "        request = urllib2.Request(link)\n",
      "        response = urllib2.urlopen(request)\n",
      "        page = response.read()\n",
      "        soup = BeautifulSoup(page)\n",
      "        links = soup.find_all(id = 'pdfDocument')\n",
      "        nlinks = len(links)\n",
      "        if (nlinks > 1):\n",
      "            print \"More than one PDF found! Check %2d: %s\" % (i, link)\n",
      "            continue\n",
      "        if (nlinks < 1):\n",
      "            print \"No Access! Check %2d: %s\" % (i, link)\n",
      "            continue\n",
      "        pdflink = links[0]['src']\n",
      "        pdfdict[i] = pdflink\n",
      "    print \"%i out of %i requested PDF files are accessible.\\n\" % (len(pdfdict), len(urldict))\n",
      "    #print pdfdict\n",
      "    return pdfdict\n",
      "\n",
      "def getpdfs(pdfdict, path = 'WileyBooks'):\n",
      "    '''\n",
      "    This function retrieves the PDF files from the server. \n",
      "    You have to run it immediately after getpdflinks(), \n",
      "    otherwise the URLs will be invalid and HTTP error 403 Forbidden is returend.\n",
      "    '''\n",
      "    # TODO error handling, HTTP 403 error\n",
      "    for key in pdfdict.keys():\n",
      "        link = pdfdict[key]\n",
      "        #print key\n",
      "        #print type(key)\n",
      "        #print link\n",
      "        request = urllib2.Request(link)\n",
      "        response = urllib2.urlopen(request)\n",
      "        page = response.read()\n",
      "        #print page\n",
      "        filename = '{:02d}'.format(key) + '.pdf'\n",
      "        filepath = os.path.join(path, filename) # TODO check if path exists/create it if needed\n",
      "        with open(filepath, \"wb\") as PDF:\n",
      "            PDF.write(page)\n",
      "\n",
      "def concatpdfs(path, title):\n",
      "    '''\n",
      "    from: https://www.binpress.com/tutorial/manipulating-pdfs-with-python/167\n",
      "    '''\n",
      "    merger = PdfFileMerger()\n",
      "    files = [x for x in os.listdir(path) if x.endswith('.pdf')]\n",
      "    for fname in sorted(files):\n",
      "        # TODO add blank pages between chapters if needed\n",
      "        merger.append(PdfFileReader(open(os.path.join(path, fname), 'rb')))\n",
      "    \n",
      "    # TODO get title from webpage\n",
      "    title = title[0:30] # long filenames are bad\n",
      "    # TODO check if title already has an extension\n",
      "    filename = title + '.pdf'\n",
      "    filepath = os.path.join(path, filename)\n",
      "    merger.write(filepath)\n",
      "    # TODO get wd and tell user the absolute path\n",
      "    print \"Saved combined PDF files as '%s' in '%s'\" % (filename, path)\n",
      "\n",
      "def getwileybook(url, path, title):\n",
      "    # TODO check if path exists/is absolute/create it if needed\n",
      "    # TODO check title\n",
      "    urldict = getlinks(url)\n",
      "    pdfdict = getpdflinks(urldict)\n",
      "    getpdfs(pdfdict, path)\n",
      "    concatpdfs(path, title)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'http://onlinelibrary.wiley.com/book/10.1002/047086799X'\n",
      "path = 'WileyBooks/ModWeb'\n",
      "title = 'Modeling the Internet and the Web'\n",
      "\n",
      "urldict = getlinks(url)\n",
      "pdfdict = getpdflinks(urldict)\n",
      "getpdfs(pdfdict, path)\n",
      "concatpdfs(path, title)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 13 chapters for your request.\n",
        "\n",
        "13 out of 13 requested PDF files are accessible.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "getwileybook(url = 'http://onlinelibrary.wiley.com/book/10.1002/9780470569962', \n",
      "             path = 'WileyBooks/EvoIntSys', \n",
      "             title = 'Evolving Intelligent Systems')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 22 chapters for your request.\n",
        "\n",
        "22 out of 22 requested PDF files are accessible.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Saved combined PDF files as Evolving Intelligent Systems.pdf in WileyBooks/EvoIntSys"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files = [x for x in os.listdir(path) if x.endswith('.pdf')]\n",
      "sorted(files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "[' 0.pdf',\n",
        " ' 1.pdf',\n",
        " ' 2.pdf',\n",
        " ' 3.pdf',\n",
        " ' 4.pdf',\n",
        " ' 5.pdf',\n",
        " ' 6.pdf',\n",
        " ' 7.pdf',\n",
        " ' 8.pdf',\n",
        " ' 9.pdf',\n",
        " '10.pdf',\n",
        " '11.pdf',\n",
        " '12.pdf',\n",
        " 'Modeling the Internet and the Web.pdf']"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "getwileybook(url = 'http://onlinelibrary.wiley.com/book/10.1002/0471227587', \n",
      "             path = 'WileyBooks/DNA-MAD', \n",
      "             title = 'Analysis of DNA Microarray Data')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 16 chapters for your request.\n",
        "\n",
        "16 out of 16 requested PDF files are accessible.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Saved combined PDF files as 'Analysis of DNA Microarray Dat.pdf' in 'WileyBooks/DNA-MAD'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "getwileybook(url = 'http://onlinelibrary.wiley.com/book/10.1002/0471671746', \n",
      "             path = 'WileyBooks/GenAlg', \n",
      "             title = 'Practical Genetic Algorithms')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 13 chapters for your request.\n",
        "\n",
        "13 out of 13 requested PDF files are accessible.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Saved combined PDF files as 'Practical Genetic Algorithms,.pdf' in 'WileyBooks/GenAlg'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 34
    }
   ],
   "metadata": {}
  }
 ]
}